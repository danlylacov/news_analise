#!/usr/bin/env python3
"""
–ò—Ç–æ–≥–æ–≤—ã–π —Ç–µ—Å—Ç —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç-–∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import requests
import pandas as pd
import json
import time
from datetime import datetime

def test_all_data_with_sentiment():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç-–∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    url = "http://localhost:8000"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API
    try:
        response = requests.post(f"{url}/health", json={})
        if response.status_code == 200:
            print("‚úÖ API –¥–æ—Å—Ç—É–ø–µ–Ω")
        else:
            print("‚ùå API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API: {e}")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
    print("üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ...")
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏
        train_news = pd.read_csv('datasets/raw/train_news.csv', nrows=1000)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞
        train_candles = pd.read_csv('datasets/raw/train_candles.csv', nrows=2000)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(train_news)} –Ω–æ–≤–æ—Å—Ç–µ–π –∏ {len(train_candles)} —Å–≤–µ—á–µ–π")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è API
    print("üîÑ –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è API...")
    
    news_data = [
        {
            "title": str(row['title']),
            "publication": str(row['publication']),
            "publish_date": str(row['publish_date'])
        }
        for _, row in train_news.iterrows()
    ]
    
    candles_data = [
        {
            "ticker": str(row['ticker']),
            "begin": str(row['begin']),
            "open": float(row['open']),
            "high": float(row['high']),
            "low": float(row['low']),
            "close": float(row['close']),
            "volume": int(row['volume'])
        }
        for _, row in train_candles.iterrows()
    ]
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç-–∞–Ω–∞–ª–∏–∑–æ–º
    print("\nüîç –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç-–∞–Ω–∞–ª–∏–∑–æ–º...")
    
    request_data = {
        "news": news_data,
        "candles": candles_data,
        "artifacts_dir": "artifacts",
        "p_threshold": 0.3,
        "half_life_days": 0.5,
        "max_days": 2.0,
        "add_sentiment": True
    }
    
    start_time = time.time()
    
    try:
        response = requests.post(f"{url}/infer", json=request_data, timeout=300)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        if response.status_code == 200:
            result = response.json()
            
            print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {processing_time:.2f} —Å–µ–∫")
            print(f"üìä –°—Ç–∞—Ç—É—Å: {result.get('status', 'unknown')}")
            print(f"üìä –°—Ç—Ä–æ–∫ –≤ —Ñ–∏—á–∞—Ö: {result.get('rows_features', 0)}")
            print(f"üìä –°—Ç—Ä–æ–∫ –≤ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {result.get('rows_joined', 0)}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if result.get('features_preview'):
                features_df = result['features_preview']
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç-–∫–æ–ª–æ–Ω–æ–∫
                sentiment_cols = [col for col in features_df[0].keys() if 'sentiment' in col]
                print(f"\nüìà –°–µ–Ω—Ç–∏–º–µ–Ω—Ç-–∫–æ–ª–æ–Ω–∫–∏: {sentiment_cols}")
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                total_news = sum(f.get('nn_news_count', 0) for f in features_df)
                records_with_sentiment = sum(1 for f in features_df if f.get('sentiment_count', 0) > 0)
                
                print(f"   –í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_news}")
                print(f"   –ó–∞–ø–∏—Å–µ–π —Å —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–æ–º: {records_with_sentiment}")
                
                if records_with_sentiment > 0:
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-5 –∑–∞–ø–∏—Å–µ–π —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –Ω–æ–≤–æ—Å—Ç–µ–π
                    print(f"\nüèÜ –¢–æ–ø-5 –∑–∞–ø–∏—Å–µ–π —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏:")
                    sorted_features = sorted(features_df, key=lambda x: x.get('nn_news_count', 0), reverse=True)
                    
                    for i, feature in enumerate(sorted_features[:5], 1):
                        print(f"   {i}. –¢–∏–∫–µ—Ä: {feature.get('ticker', 'N/A')}, –î–∞—Ç–∞: {feature.get('date', 'N/A')}")
                        print(f"      –ù–æ–≤–æ—Å—Ç–µ–π: {feature.get('nn_news_count', 0)}")
                        print(f"      –°–µ–Ω—Ç–∏–º–µ–Ω—Ç (—Å—Ä–µ–¥–Ω–∏–π): {feature.get('sentiment_mean', 0):.3f}")
                        print(f"      –ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö: {feature.get('sentiment_positive_count', 0)}")
                        print(f"      –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö: {feature.get('sentiment_negative_count', 0)}")
                        print(f"      –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö: {feature.get('sentiment_neutral_count', 0)}")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç—É
                sentiment_means = [f.get('sentiment_mean', 1.0) for f in features_df if f.get('sentiment_count', 0) > 0]
                if sentiment_means:
                    avg_sentiment = sum(sentiment_means) / len(sentiment_means)
                    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞:")
                    print(f"   –°—Ä–µ–¥–Ω–∏–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç: {avg_sentiment:.3f}")
                    print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π: {min(sentiment_means):.3f}")
                    print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π: {max(sentiment_means):.3f}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"api_response_all_data_sentiment_{timestamp}.json"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {output_file}")
            print(f"üìà –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f} —Å–µ–∫")
            print(f"üìä –°–∫–æ—Ä–æ—Å—Ç—å: {len(news_data)/processing_time:.1f} –Ω–æ–≤–æ—Å—Ç–µ–π/—Å–µ–∫")
            
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
            print(f"–û—Ç–≤–µ—Ç: {response.text}")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    print("üöÄ –ò—Ç–æ–≥–æ–≤—ã–π —Ç–µ—Å—Ç —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç-–∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö")
    print("=" * 60)
    test_all_data_with_sentiment()
