{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FORECAST: Новости → Тикеры → Влияние на свечи (Kaggle)\n",
        "\n",
        "Перед запуском:\n",
        "- В Settings → Accelerator включите GPU (опционально, можно и CPU).\n",
        "- Загрузите ваш проект как Kaggle Dataset (весь каталог с .py скриптами и CSV).\n",
        "\n",
        "Ноутбук автоматически найдёт каталог в `/kaggle/input/` и скопирует файлы в `/kaggle/working`. Дальше:\n",
        "1) Установка зависимостей\n",
        "2) Копирование проекта\n",
        "3) Авторазметка `tickers` для новостей\n",
        "4) Обучение нейросети (BiGRU+attention)\n",
        "5) Инференс: агрегаты влияния новостей на свечи\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "pip install -q pandas==2.2.2 numpy==1.26.4 pyarrow==16.1.0 scikit-learn==1.5.1 razdel==0.5.0 pymorphy3==2.0.2 pymorphy3-dicts-ru==2.4.417150.4580142 rapidfuzz==3.9.6 emoji==2.12.1 text-unidecode==1.3 torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, shutil, glob\n",
        "from pathlib import Path\n",
        "\n",
        "INPUT_ROOT = Path('/kaggle/input')\n",
        "WORK = Path('/kaggle/working')\n",
        "\n",
        "# Найдём ваш датасет по имени каталога с проектом (ищем news_analize)\n",
        "src = None\n",
        "for p in INPUT_ROOT.glob('**/*'):\n",
        "    if p.is_dir() and p.name.lower().startswith('news_analize'):\n",
        "        src = p\n",
        "        break\n",
        "if src is None:\n",
        "    # fallback: если датасет назван иначе, берём первый каталог\n",
        "    for p in INPUT_ROOT.iterdir():\n",
        "        if p.is_dir():\n",
        "            src = p\n",
        "            break\n",
        "print('SRC:', src)\n",
        "\n",
        "# Копируем файлы проекта в рабочую директорию\n",
        "for f in src.rglob('*'):\n",
        "    rel = f.relative_to(src)\n",
        "    dest = WORK / rel\n",
        "    if f.is_dir():\n",
        "        dest.mkdir(parents=True, exist_ok=True)\n",
        "    else:\n",
        "        dest.parent.mkdir(parents=True, exist_ok=True)\n",
        "        shutil.copy2(f, dest)\n",
        "print('Files copied to', WORK)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Авторазметка тикеров\n",
        "!python auto_label_tickers.py --news test_news.csv --out task_1_news_autolabeled.csv\n",
        "\n",
        "# Быстрая проверка наличия столбца tickers\n",
        "import pandas as pd\n",
        "x = pd.read_csv('task_1_news_autolabeled.csv')\n",
        "print(x.columns.tolist()[:10])\n",
        "print(x[['publish_date','title','tickers']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Обучение модели новости→тикеры\n",
        "!python train_news_ticker.py --news task_1_news_autolabeled.csv --artifacts artifacts/ --epochs 3 --batch_size 64 --max_len 256\n",
        "\n",
        "# Проверим артефакты\n",
        "import os\n",
        "print('Artifacts:', os.listdir('artifacts'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Инференс влияния на свечи\n",
        "# При необходимости замените имена CSV на ваши (public_test_candles.csv / task_1_candles.csv)\n",
        "!python infer_news_to_candles.py \\\n",
        "  --news task_1_news_autolabeled.csv \\\n",
        "  --candles public_test_candles.csv \\\n",
        "  --artifacts artifacts/ \\\n",
        "  --out nn_features.parquet\n",
        "\n",
        "import pandas as pd\n",
        "print(pd.read_parquet('nn_features.parquet').head())\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
